{
    "<DATA SOURCE>" : "<CLIENT NAME> is using Cribl Stream to enrich its <DATA SOURCE> data before it is sent to Splunk. The goal is to replace the heavy forwarders with the following Cribl Stream pipeline. Currently, we have 11.61TB in/day of PCF data in production. This use case will be deployed in the HEC-Syslog worker group.\n\nBefore reaching Splunk, the following metadata fields will be attached to each event in the <NAME> pipeline.",
    "Windows / AD Events" : "<CLIENT NAME> will be utilizing a customized version of the Cribl Microsoft Windows Events Pack to clean the data before it is sent to Splunk, but will also create a pipeline to append the correct host, <TAGS> and index tags via a Lookup table. Currently, we have <SIZE> in/day of Windows AD data in production. This use case will be deployed in the <WORKER GROUP 1>  worker group.",
    "<SAMPLE> Logs" : "<CLIENT NAME> is using Cribl Stream to aggregate both processed and dropped logs for various sourcetypes for their data. Sourcetypes are either dropped or processed based on specific filtering, and then the aggregated count and byte size is sent to Splunk from a 60 minute window. Data is flowing in via the Splunk UF source in the <WORKER GROUP 1> worker group. Currently, we have ## in and ### out/day of logs in production.",
    "Best Practices & Recommendations" : "The following are best practices and recommendations based on the above Cribl Stream configurations.",
    "GitOps" : "<CLIENT NAME> can integrate configuration management of their Cribl Stream with standard version-control systems and CI/CD flow, which will allow them to push updates to their remote Cribl Stream via automation. The following are recommended best practices:\n\t- A Cribl Stream GitOps deployment can start with an existing repository, or you can set up an entirely new repo and start fresh from there. If you're already using an existing remote repo for your Cribl Stream deployment, Cribl recommends cloning a backup.\n\t- Create at least one branch for your production code. You will merge code into this branch and use it to update your production Cribl Stream environment.\n\t- To ensure that dev- and production-specific settings don't get enabled in both environments, you can use environment details to define what Sources and Destinations are used in which environment. Here's how: https://docs.cribl.io/logstream/gitops/#env-var\n\t- Cribl recommends that you also create a separate dev branch for your code. This is where you will sync and work in your development environment. Once changes are validated and tested in dev, you can merge them into production.",
    "Persistent Queues" : ["<CLIENT NAME> will set their load balanced Splunk destinations to the persistent queuing option, which helps minimize data loss if a downstream receiver is unreachable; once the in-memory queue is full, the Cribl Stream Destination will write its data to disk. Then, when the receiver is ready, the output will start draining the queues in FIFO (first in, first out) fashion. The following are details and constraints around the queuing feature:\n\n\t- Engaged only when all of the Destination's receivers are blocking data flow. (A single live receiver will prevent PQ from engaging on the corresponding Destination.)\n\t- Drained when at least one receiver can accept data.\n\t- Not infinite in size. I.e., if data cannot be delivered out, you might run out of disk space.\n\t- Not able to fully protect in cases of application failure. E.g., in-memory data might get lost if a crash occurs. \n\t- Not able to protect in cases of hardware failure. E.g., disk failure, corruption, or machine/host loss.\n\t- For queuing to operate properly, you must provide sufficient disk space.","example1.png"],
    "Upgrading" : "For a distributed deployment, the general order of upgrade is: First upgrade the Leader Node, then upgrade the Worker Nodes, then commit and deploy the changes on the Leader. Workers' UI will not be available until the Worker version has been upgraded to match the version on the Leader. It is important to note that you should always check for any uncommitted/unpushed changes before starting the upgrades. Errors like those below will appear until the Worker nodes are upgraded.",
    "Splunk Load Balancing" : "<CLIENT NAME> will utilize the Splunk Load Balanced option in order to load-balance data out to multiple Splunk receivers. Cribl Stream will attempt to load-balance outbound data as fairly as possible across all receivers (listed as Destinations in the GUI). Data is sent by all worker processes to all receivers simultaneously, and the amount sent to each receiver depends on these parameters:\n\n\t- Respective destination weight\n\t- Respective destination historical data\n\nBy default, historical data is tracked for 300s. Cribl Stream uses this data to influence the traffic sent to each destination, to ensure that differences decay over time, and that total ratios converge towards configured weights.",
    "Max File Options" : "For the following destination types, you will want to configure the max file options in order to avoid errors: Filesystem/NFS, Azure Blob, Google Cloud and Amazon S3.\n\t- Raise the number of open files to avoid 'too many open files' errors. Linux's default maximum open files is generally 1024 open files per process, with 2048 as the maximum. When Cribl Stream is set to boot on system start through systemd (as all installations should be), the systemd unit file, cribl.service must be updated with a line similar to this: LimitNOFILE=2048. Merely updating /etc/limits.conf is not enough. If you have a high cardinality partition expression, raise this setting to accommodate the larger numbers of files that will be created.\n\t- Adjust the max file size (uncompressed size), max file open time, and max file idle time as necessary. If you don't mind more than 1 minute delay with the files reaching S3, increase the max file size and max file open time, and ensure the max open files setting is sufficient. It's not uncommon to set max open files to 2000; note that number is per worker process.",
    "Routes and Pipelines" : "- Routes are designed to filter, clone, and cascade incoming data across a related set of Pipelines and Destinations. If all you need are independent connections that link parallel Source/Destination pairs, you can use Cribl Stream's QuickConnect rapid visual configuration tool as an alternative to Routes.\n- Design data paths to move through as few Routes as possible. This usually means we want to reduce the volume of events as early as possible. If most of the events being processed are sent to a Destination by the first Route, this will spare all the other Routes and Pipelines wasted processing cycles and testing against whether filter criteria are met.\n\t- Create a catchall Route at the end of the list to explicitly route events that fail to match any Route filters.\n\t- While not required, it is recommended that you use filters as often as possible in your pipeline functions.\n\t- Do not use the same Pipeline for both pre-processing and post-processing. This makes isolation and troubleshooting extremely difficult.\n\t- As with Routes, the general goal is to minimize extra work that a Function will do. The fewer events a Function has to operate on, the better the overall performance.\n\t- Consider avoiding the use of _raw as a temporary location for data. Instead, split out explicitly separate fields/variables."
}